{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429cda68",
   "metadata": {},
   "source": [
    "# Understanding Airbnb activity in Rio de Janeiro, Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a8a39",
   "metadata": {},
   "source": [
    "This project demonstrate the analysis of Rio de Janeiro Airbnb data using CRISP-DM process.\n",
    "\n",
    "CRISP-DM which stands for Cross-Industry Standard Process for Data Mining is an industry standard.\n",
    "\n",
    "\n",
    "### About Data\n",
    "\n",
    "Data being used in this notebook can be found [here](http://insideairbnb.com/get-the-data/), where files pertinent to current analysis include:\n",
    "\n",
    "* listings: which is summary information of the detailed listings\n",
    "* detailed_listings: comprehensive information about listings in Rio\n",
    "* calendar: includes the calendar data for the above listings\n",
    "\n",
    "\n",
    "### Questions of Interest\n",
    "\n",
    "\n",
    "\n",
    "1) What is the most expensive month to visit Rio de Janeiro?\n",
    "---\n",
    "\n",
    "2) Most and least expensive Neighbourhood in Rio de Janeiro?\n",
    "---\n",
    "\n",
    "\n",
    "3) What are the factors associated with price of listings?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538a152",
   "metadata": {},
   "source": [
    "## Basic Information of Data\n",
    "\n",
    "This section consist of some basic understanding of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8ed39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae45223",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Rio/listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read in listings data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m listings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRio/listings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Rio/listings.csv'"
     ]
    }
   ],
   "source": [
    "# read in listings data\n",
    "\n",
    "listings = pd.read_csv('Rio/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277cc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look into the dataframe\n",
    "\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Printing Rio de Janeiro listing summary info: ')\n",
    "print(\" \")\n",
    "listings.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns with no missing values \n",
    "\n",
    "listings.columns[listings.isnull().mean() == 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091524b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns with 75% of missing values\n",
    "\n",
    "listings.columns[listings.isnull().mean() > 0.75].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of room_type column\n",
    "\n",
    "room_type = listings.room_type.value_counts()\n",
    "print(room_type)\n",
    "\n",
    "(room_type/listings.shape[0]).plot(kind = 'bar')\n",
    "plt.title(\"Types of rooms\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping neighborhoods by a higher-level category\n",
    "# Top N neighborhoods\n",
    "top_n = 20 # You can adjust this value as needed\n",
    "neighbourhood_counts = listings['neighbourhood'].value_counts()\n",
    "print('Total number of neighbourhoods: ', len(neighbourhood_counts))\n",
    "\n",
    "# Plotting\n",
    "neighbourhood_counts.head(20).plot(kind='barh')\n",
    "plt.title(\"Top {} Neighborhoods\".format(top_n))\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Neighborhood\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest count at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of num of reviews\n",
    "\n",
    "listings.number_of_reviews.hist(edgecolor = 'black')\n",
    "plt.title(\"distribution\")\n",
    "plt.xlabel(\"no. of reviews\")\n",
    "plt.ylabel(\"frequency of no. of reviews\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of price\n",
    "\n",
    "# Histogram with KDE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(listings['price'], kde=True, bins=30)\n",
    "plt.title('Price Distribution with KDE')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=listings['price'])\n",
    "plt.title('Price Distribution (Box Plot)')\n",
    "plt.xlabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# Violin Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=listings['price'], inner='quartile')\n",
    "plt.title('Price Distribution (Violin Plot)')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# ECDF Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.ecdfplot(data=listings, x='price')\n",
    "plt.title('Empirical Cumulative Distribution Function (ECDF) of Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c184d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some statistical info\n",
    "\n",
    "numerical_columns = listings.select_dtypes(include=['number']).columns.to_list()\n",
    "numerical_columns = numerical_columns[5:]\n",
    "\n",
    "listings[numerical_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2e25e",
   "metadata": {},
   "source": [
    "This sums up the listings summary which contains 36008 row and 18 columns that covers the basic details such as id, name(client and host), location(latitude and longitude), monthly reviews and price according to the various factors.\n",
    "\n",
    "\n",
    "### insights into data\n",
    "\n",
    "* We found the total number of neighbourhood is 156 with copacabana having most of the listings.\n",
    "* We found almost 80% of listings are entire home/ apartment while around 17-18% are private room.\n",
    "* minimum nights has an average value of 4.41 and max value of 1125 which ofcourse is an indication of error.\n",
    "* price is long tail skewed to the right with an average of 1211 and max of 552637.\n",
    "* we also found that neighbourhood_group column consist of all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe46439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rio de Janeiro calendar data\n",
    "calendar = pd.read_csv('Rio/calendar.csv')\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214679b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a100aae",
   "metadata": {},
   "source": [
    "### Calender data\n",
    "\n",
    "Nothing much to mention in this calendar dataset as one can see, we have listing id, date, availability and price with no null value, while mininum and maximum nights consists of few null values.\n",
    "\n",
    "* We can notice that date columns is in string format and needs to be changed in date format.\n",
    "* price is also a string which needs modification as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e0981",
   "metadata": {},
   "source": [
    "## Detailed Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c489f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rio de Janeiro detailed listing data\n",
    "\n",
    "detailed_listings = pd.read_csv('Rio/detailed_listings.csv')\n",
    "detailed_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some info about data\n",
    "\n",
    "print(\"No. of rows: \", detailed_listings.shape[0])\n",
    "print(\"No. of columns: \", detailed_listings.shape[1])\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "detailed_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7159775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#columns with no missing values\n",
    "\n",
    "detailed_listings.columns[detailed_listings.isnull().mean() == 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns with more than 75% of missing values\n",
    "\n",
    "detailed_listings.columns[detailed_listings.isnull().mean() > 0.75].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns with 100% missing values\n",
    "\n",
    "detailed_listings.columns[detailed_listings.isnull().mean() == 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ffd8f",
   "metadata": {},
   "source": [
    "This detailed Rio de Janeiro listing consits 36008 rows and 75 columns, where we can notice we almost have every columns from listings summary dataframe with addition of 57 more columns.\n",
    "\n",
    "Things to consider in Wrangling phase:\n",
    "\n",
    "* we will eliminate few columns which does not contribute to our question of interest as well columns with more than 75% of missing values\n",
    "* Handle missing values and categorical variables\n",
    "* we will also look over the issues in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6b437",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### Calendar dataset\n",
    "* change the date column format from string to datetime.\n",
    "* change the format of Price column from string to numerical (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6138b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date column format\n",
    "\n",
    "calendar.date = pd.to_datetime(calendar.date)\n",
    "calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the rows in calendar dataset where price has missing values\n",
    "calendar = calendar.dropna(subset = ['price'], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95026a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverts price into float format\n",
    "\n",
    "def clean_price(price):\n",
    "    \n",
    "    '''\n",
    "    cleans the price columns by removing '$' from price and\n",
    "    then converting string to float.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        if ',' in price:\n",
    "            price = price.replace(',','')\n",
    "        \n",
    "        price = price[1:]\n",
    "        return float(str(price))\n",
    "    except:\n",
    "        return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b51da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cleans the price and convert it into float\n",
    "calendar['price'] = calendar.price.apply(lambda x: clean_price(x))\n",
    "calendar.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c023d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94db766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null column\n",
    "\n",
    "calendar = calendar.drop(columns = ['adjusted_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf140cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make month and year columns from date \n",
    "calendar['month'], calendar['year'] = calendar.date.dt.month, calendar.date.dt.year\n",
    "calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875a36f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934ce30",
   "metadata": {},
   "source": [
    "# Going back to our questions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85adea",
   "metadata": {},
   "source": [
    "### 1) Most expensive months to visit Rio de Janeiro \n",
    "\n",
    "analyzing the average price of listings available every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546ea13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar.available.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b521f3",
   "metadata": {},
   "source": [
    "* Looks like we have a good amount of split between available and unvailable listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_available_mask = calendar.available == 'f'\n",
    "available_mask = calendar.available == 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d911cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total house count daily throughout the year\n",
    "daily_available_count = calendar[available_mask].groupby('date').count()[['price']]\n",
    "daily_available_count = daily_available_count.rename({'price':\"total_available_houses\"}, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average price of above house daily throughout the year\n",
    "daily_average_price = calendar[available_mask].groupby('date').mean()[['price']]\n",
    "daily_average_price = daily_average_price.rename({\"price\":\"average_price\"},axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc92a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting total available house and their average price along a year\n",
    "f, ax = plt.subplots(figsize = (15, 6))\n",
    "\n",
    "\n",
    "\n",
    "plt_1 = sns.lineplot(x = daily_available_count.index, y = \"total_available_houses\",\n",
    "                   data = daily_available_count, color = 'r', legend = False)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "plt_2 = sns.lineplot(x = daily_average_price.index, y = \"average_price\",\n",
    "                    data = daily_average_price, ax = ax2, color = 'b', legend = False)\n",
    "\n",
    "ax.legend(['Total Available Houses'], loc='upper right')\n",
    "ax2.legend(['Average Price'], loc='upper right', bbox_to_anchor = (0.939,0.92))\n",
    "\n",
    "\n",
    "ax.set_title('Comparing the daily availability of Rio listing with the daily average prices')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average price of listings by month\n",
    "monthly_average_price = calendar[available_mask].groupby('month').mean()[['price']]\n",
    "monthly_average_price = monthly_average_price.rename({'price':'monthly_average_price'}, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cec701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#house counts by months\n",
    "monthly_available_count = calendar[available_mask].groupby('month').count()[['price']]\n",
    "monthly_available_count = monthly_available_count.rename({'price':'monthly_available_house_count'},axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ad901",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (15, 6))\n",
    "plt_1 = sns.lineplot(x = monthly_available_count.index, y = 'monthly_available_house_count',\n",
    "                    data = monthly_available_count, color ='r', legend = False)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "plt_2 = sns.lineplot(x = monthly_average_price.index, y= 'monthly_average_price',\n",
    "                    data = monthly_average_price, ax = ax2, color = 'b', legend = False)\n",
    "\n",
    "ax.legend(['available houses by month'], loc = 'upper right', bbox_to_anchor = (1, 0.8))\n",
    "ax2.legend(['monthly average price'], loc = 'upper right', bbox_to_anchor = (1, 0.88))\n",
    "\n",
    "ax.set_title('Comparing monthly available house count with their average price');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af76cd",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "\n",
    "* One can notice that there is clear correlation between total available houses and their average price.\n",
    "* Low availability causing the price to go up and vice versa.\n",
    "* There is clear trend and seasonality in daily average price and availability, which is very unstable at the start of the year and it gets consistent in the middle of the year.\n",
    "* Average monthly price soars up at the end of the year, assuming the new year hype, while cheapest months to book listing between February and April."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207040f6",
   "metadata": {},
   "source": [
    "### 2) Most and least expensive Neighbourhood in boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ff93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the avg. listing price according the neighbourhood\n",
    "Expensive_neighbourhood = listings.groupby(['neighbourhood'])['price'].mean().sort_values(ascending = False).nlargest(20)\n",
    "Expensive_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a178f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_expensive_neighbourhood =listings.groupby(['neighbourhood'])['price'].mean().sort_values(ascending = True)\n",
    "least_expensive_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting figure size and bar color\n",
    "plt.figure(figsize = (10,6))\n",
    "bar_color = 'skyblue'\n",
    "Expensive_neighbourhood.plot(kind = 'bar' , color= bar_color)\n",
    "\n",
    "#setting grid attribute and getting rid of unnecessary graph border\n",
    "plt.grid(axis = 'y', linestyle = '--', alpha = 0.7)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#Title\n",
    "plt.title('Expensive Neighbourhood')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Neighbourhood')\n",
    "\n",
    "#preventing overlapping layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d3e80",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "* As one can see, the most expensive Rio Neighbourhood is <b> São Cristóvão </b>, followed by <b>Estácio </b> and <b>Joá</b>.\n",
    "* While the least expensive Neighbourhood is <b>Mangueira</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc1e32c",
   "metadata": {},
   "source": [
    "## 3) What are the factors associated with price of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8389ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.info(max_cols = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the redundant the column\n",
    "detailed_listings.drop(columns = 'neighbourhood', inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd85f79",
   "metadata": {},
   "source": [
    "### Handling the missing values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd0dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dropping columns with more than 75% of missing values\n",
    "\n",
    "cols_with_missing_val = list(set(detailed_listings.columns[detailed_listings.isnull().mean()>0.75]))\n",
    "print(\"columns with 75% of missing values:\",cols_with_missing_val)\n",
    "\n",
    "print('-'*80)\n",
    "\n",
    "detailed_listings.drop(columns = cols_with_missing_val, inplace =True, axis = 1)\n",
    "detailed_listings.info(max_cols = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385390fe",
   "metadata": {},
   "source": [
    "### Handling text columns\n",
    "\n",
    "* Create additional binary columns to indicate whether specific column values are present in the existing columns for <b>neighborhood_overview</b>, <b>host_about</b>.\n",
    "\n",
    "* Replace \"t\" and \"f\" values categorical columns with binary version of same for <b>host_is_superhost, instant_bookable, host_identity_verified, host_has_profile_pic</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['has_neighborhood_info'] = detailed_listings.neighborhood_overview.apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "detailed_listings['has_host_info'] = detailed_listings.host_about.apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "#fixing t and f columns\n",
    "detailed_listings['host_is_superhost'] = detailed_listings.host_is_superhost.apply(lambda x: 1 if x == 't' else 0)\n",
    "detailed_listings['instant_bookable'] = detailed_listings.instant_bookable.apply(lambda x: 1 if x == 't' else 0)\n",
    "detailed_listings['host_identity_verified'] = detailed_listings.host_identity_verified.apply(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.info(max_cols = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d42f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping redundant columns\n",
    "redundant_columns = ['id','scrape_id','host_id','has_availability','host_picture_url','host_neighbourhood',\n",
    "                     'listing_url','last_scraped','host_about','host_verifications',\n",
    "                     'name','host_name','neighborhood_overview','calendar_last_scraped',\n",
    "                     'host_url','host_thumbnail_url','host_location','amenities',\n",
    "                     'picture_url','host_has_profile_pic','source','host_total_listings_count']\n",
    "print('Redundant_columns:',redundant_columns)\n",
    "print('--'*45)\n",
    "detailed_listings.drop(columns = redundant_columns, inplace = True)\n",
    "detailed_listings.info(max_cols = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a37574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remaining object columns in dataframe\n",
    "detailed_listings.select_dtypes(include = ['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc755a83",
   "metadata": {},
   "source": [
    "### We can concat some types into one group for some features which occurs less as it will increase the complexity of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the display settings to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the value counts for the 'property_type' column\n",
    "print(detailed_listings['property_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the display settings to default\n",
    "pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc396a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#feature engineering for property_type column\n",
    "property_value_counts = detailed_listings.property_type.value_counts()\n",
    "values_to_replace = property_value_counts[property_value_counts<100].index\n",
    "detailed_listings.property_type.replace(values_to_replace, 'other_types', inplace = True)\n",
    "detailed_listings.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "detailed_listings.room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f59a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.bathrooms_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b66190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59aa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#feature engineering for bathrooms_text column\n",
    "bathrooms_value_counts = detailed_listings.bathrooms_text.value_counts()\n",
    "values_to_replace = bathrooms_value_counts[bathrooms_value_counts<150].index\n",
    "detailed_listings.bathrooms_text.replace(values_to_replace, 'other_bathrooms_text', inplace = True)\n",
    "detailed_listings.bathrooms_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "detailed_listings.neighbourhood_cleansed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering for neighbourhood_cleansed column\n",
    "neighbourhood_value_counts = detailed_listings.neighbourhood_cleansed.value_counts()\n",
    "values_to_replace = neighbourhood_value_counts[neighbourhood_value_counts<150].index\n",
    "detailed_listings.neighbourhood_cleansed.replace(values_to_replace, 'other_neighbourhoods', inplace = True)\n",
    "detailed_listings.neighbourhood_cleansed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948def02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Numerical columns in dataframe\n",
    "numerical_columns = detailed_listings.select_dtypes(include = ['float', 'int']).columns\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fe4e5",
   "metadata": {},
   "source": [
    "### Before proceeding with any analysis or modeling task, it's crucial to address missing data and enhance the quality of our dataset\n",
    "\n",
    "* Handling missing values and improving quality of specific columns through feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec54e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows of dataframe where price is missing\n",
    "print(\"missing values in price column: \",detailed_listings['price'].isnull().sum())\n",
    "detailed_listings = detailed_listings.dropna(subset=['price'], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e16d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#missing values in each features\n",
    "detailed_listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop missing rows from review related columns\n",
    "review_related_cols = ['review_scores_checkin','review_scores_location','review_scores_value']\n",
    "detailed_listings = detailed_listings.dropna(subset = review_related_cols,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce271f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings = detailed_listings.dropna(subset = 'reviews_per_month', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df80782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detailed_listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af061921",
   "metadata": {},
   "source": [
    "Looking at those metrics for different columns, we can conclude that our dataset has tons of outliers and unstable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the maximum limit value, beyond which data points can be considered outliers.\n",
    "def get_max_fence(column):\n",
    "    qt = detailed_listings[column].quantile([0.25,0.75])\n",
    "    upper = qt.values[1]\n",
    "    iqr = upper-qt.values[0]\n",
    "    max_fence = upper + 1.5*(iqr)\n",
    "    return max_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb90f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns two seaborn boxplots with one zoomed in around interquartile range\n",
    "def box_plot(column):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(16,6)\n",
    "    _ = sns.boxplot(x=detailed_listings[column], ax = ax1)\n",
    "    ax1.set_title(f'{column} boxplot')\n",
    "    ax2.set_title(f'Zooming in the {column} boxplot')\n",
    "    ax2.set_xlim((-0.1,1.1*get_max_fence(column)))\n",
    "    _ = sns.boxplot(x=detailed_listings[column], ax = ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c870420",
   "metadata": {},
   "source": [
    "Cleaning and Transforming <b>host_listings_count</b> column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699c53f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_plot('host_listings_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(detailed_listings.host_listings_count, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7dcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_fence('host_listings_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49f0e4",
   "metadata": {},
   "source": [
    "Based on the selected method, any values exceeding 13.5 are considered outliers. Given the substantial presence of outliers in the dataset, a decision has been made to exclude them from the analysis. As the primary objective of the study is to identify the factors influencing prices, removing outliers ensures a more accurate examination of the underlying relationships and patterns within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = detailed_listings.shape[0]\n",
    "detailed_listings = detailed_listings[detailed_listings['host_listings_count'] <= get_max_fence('host_listings_count')]\n",
    "print(f'{rows_before-detailed_listings.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832eb90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(detailed_listings.host_listings_count, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f308784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = skew(detailed_listings.host_listings_count)\n",
    "\n",
    "print(\"Skewness:\", skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e04bd",
   "metadata": {},
   "source": [
    "As we can see, datapoints are heavily skewed, we will tranform our data to bring the skewness down and make it more normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938068c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log transformation for positive skew data\n",
    "#detailed_listings['host_listings_count'] = [math.log1p(d) for d in detailed_listings.host_listings_count]\n",
    "#sns.distplot(detailed_listings.host_listings_count, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c525ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skew(detailed_listings.host_listings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "detailed_listings['host_listings_count'],lam = boxcox(detailed_listings.host_listings_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2762bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(detailed_listings.host_listings_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506a510",
   "metadata": {},
   "source": [
    "We are able to bring skewness down 0.25 from almost 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679565f",
   "metadata": {},
   "source": [
    "### Cleaning and Transforming host_listings_count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530151",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['price'] = detailed_listings.price.apply(lambda x: clean_price(x))\n",
    "detailed_listings.price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a901ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.distplot(detailed_listings['price'],norm_hist=True)\n",
    "_ = ax.set_title('Price distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b333dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068b05d",
   "metadata": {},
   "source": [
    "tons of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_fence('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf4c57",
   "metadata": {},
   "source": [
    "This shows us that the daily prices over 1907.875 are outliers of our regression, so let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = detailed_listings.shape[0]\n",
    "detailed_listings = detailed_listings[detailed_listings['price'] <= get_max_fence('price')]\n",
    "print(f'{rows_before-detailed_listings.shape[0]} rows were removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965d28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.distplot(detailed_listings['price'],norm_hist=True)\n",
    "_ = ax.set_title('Price distribution - Outliers removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d31e78",
   "metadata": {},
   "source": [
    "distribution looks way better now, we will do some more transformation on price for positive skewness while using for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8832b7",
   "metadata": {},
   "source": [
    "### Top six property types sorted by price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf142da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aa = detailed_listings.groupby(by='property_type').mean().sort_values(by='price',ascending=False).iloc[0:6]\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(25,10)\n",
    "violin_data=detailed_listings.loc[detailed_listings['property_type'].isin(aa.index)]\n",
    "_ =  sns.barplot(x=aa.index, y='price', data=aa,ax=ax1)\n",
    "_ = ax1.set_title('Average price of property_type')\n",
    "_ = ax2.set_title('Price distribution of property_type')\n",
    "_ = sns.violinplot(x = 'property_type', y =  'price',data=violin_data,ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9e48d",
   "metadata": {},
   "source": [
    "Cleaning and Transforming <b>beds</b> column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.countplot(x='beds', data=detailed_listings)\n",
    "ax.set_xlabel('Amount of beds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot('beds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762724a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_fence('beds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = detailed_listings.shape[0]\n",
    "detailed_listings = detailed_listings[detailed_listings['beds'] <= get_max_fence('beds')]\n",
    "print(f'{rows_before-detailed_listings.shape[0]} rows were removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aef068",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.countplot(x='beds', data=detailed_listings)\n",
    "ax.set_xlabel('Amount of beds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4161cc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detailed_listings.beds.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa36ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beds_skewness = skew(detailed_listings.beds)\n",
    "beds_skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97097118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detailed_listings['beds'] = [math.log1p(d) for d in detailed_listings.beds]\n",
    "sns.distplot(detailed_listings.beds, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a57f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beds_skewness = skew(detailed_listings.beds)\n",
    "beds_skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a1379",
   "metadata": {},
   "source": [
    "Cleaning and Transforming <b>minimum_nights and maximum_nights</b> column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot('minimum_nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2dd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_fence('minimum_nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b28828",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = detailed_listings.shape[0]\n",
    "detailed_listings = detailed_listings[detailed_listings['minimum_nights'] <= get_max_fence('minimum_nights')]\n",
    "print(f'{rows_before-detailed_listings.shape[0]} rows were removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bf157",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(detailed_listings.minimum_nights, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e18531",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_nights_skewness = skew(detailed_listings.minimum_nights)\n",
    "minimum_nights_skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot('maximum_nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e104138",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_max_fence('maximum_nights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daabeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.maximum_nights.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba75dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(detailed_listings.maximum_nights, bins =20)\n",
    "max_nights_skewness = skew(detailed_listings.maximum_nights)\n",
    "max_nights_skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f75b5",
   "metadata": {},
   "source": [
    "Dropping highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['minimum_minimum_nights',\n",
    "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "       'maximum_nights_avg_ntm']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b914bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_30_skewness = skew(detailed_listings.availability_30)\n",
    "availability_60_skewness = skew(detailed_listings.availability_60)\n",
    "availability_90_skewness = skew(detailed_listings.availability_90)\n",
    "availability_365_skewness = skew(detailed_listings.availability_365)\n",
    "print(\"Printing skewness for avail_30, avail_90 and avail_365 respectively: \", availability_30_skewness,availability_60_skewness,availability_90_skewness,availability_365_skewness)\n",
    "print(\"Correlation bet. avail_30 and avail_60: \",detailed_listings.availability_30.corr(detailed_listings.availability_60))\n",
    "print(\"Correlation bet. avail_30 and avail_60: \",detailed_listings.availability_60.corr(detailed_listings.availability_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['availability_30','availability_90']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd6127",
   "metadata": {},
   "source": [
    "Cleaning and Transforming <b>number_of_reviews</b> related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings[['number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971482c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_plot('number_of_reviews')\n",
    "get_max_fence('number_of_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f6981",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(detailed_listings.number_of_reviews, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2a245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_max_fence('number_of_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f11f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = detailed_listings.shape[0]\n",
    "detailed_listings = detailed_listings[detailed_listings['number_of_reviews'] <= get_max_fence('number_of_reviews')]\n",
    "print(f'{rows_before-detailed_listings.shape[0]} rows were removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(detailed_listings.number_of_reviews, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['number_of_reviews'] = [math.log1p(d) for d in detailed_listings.number_of_reviews]\n",
    "sns.distplot(detailed_listings['number_of_reviews'], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping 'nubmer_of_reviews_ltm' because of high correlation\n",
    "print(detailed_listings.number_of_reviews.corr(detailed_listings.number_of_reviews_ltm))\n",
    "cols_to_drop =['number_of_reviews_ltm']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4689a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(detailed_listings.number_of_reviews.corr(detailed_listings.number_of_reviews_l30d))\n",
    "detailed_listings.drop(columns = ['number_of_reviews_l30d'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b75241",
   "metadata": {},
   "source": [
    "Dropping more correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ce1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = detailed_listings['host_listings_count'].corr(detailed_listings['calculated_host_listings_count'])\n",
    "print(\"Correlation between 'host_listings_count' and 'calculated_host_listings_count':\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(detailed_listings['host_listings_count'], detailed_listings['calculated_host_listings_count'])\n",
    "plt.xlabel('host_listings_count')\n",
    "plt.ylabel('calculated_host_listings_count')\n",
    "plt.title('Scatter plot of host_listings_count vs calculated_host_listings_count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop =['calculated_host_listings_count',\n",
    "       'calculated_host_listings_count_entire_homes',\n",
    "       'calculated_host_listings_count_private_rooms',\n",
    "       'calculated_host_listings_count_shared_rooms']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de77608",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = detailed_listings['review_scores_rating'].corr(detailed_listings['review_scores_value'])\n",
    "print(\"Correlation between 'review_scores_rating' and 'review_scores_value':\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['review_scores_value', 'review_scores_accuracy']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f1af8",
   "metadata": {},
   "source": [
    "Cleaning and transforming <b>host_response</b> related columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef809cf2",
   "metadata": {},
   "source": [
    "### Correct the data format \n",
    "* Transform the data type of the <b>\"first_review,\" \"last_review,\" and \"host_since\"</b> columns from string to a numerical representation indicating the number of days until the respective event.\n",
    "\n",
    "* Transform the data type of <b>\"host_response_rate\"</b> to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since(date):\n",
    "    \"\"\"\n",
    "    return the number of days since respective event\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        current_time = datetime.now()\n",
    "        d = datetime.strptime(date, date_format)\n",
    "        return abs((current_time - d).days)\n",
    "    except:\n",
    "        return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320584e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings = detailed_listings.dropna(subset =['host_response_time'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before transforming\n",
    "detailed_listings.host_since.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after transforming\n",
    "detailed_listings.host_since.apply(lambda x: days_since(x)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['first_review']= detailed_listings.first_review.apply(lambda x: days_since(x))\n",
    "detailed_listings['last_review']= detailed_listings.last_review.apply(lambda x: days_since(x))\n",
    "detailed_listings['host_since']= detailed_listings.host_since.apply(lambda x: days_since(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de3328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detailed_listings[['first_review','last_review','host_since']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2c11c",
   "metadata": {},
   "source": [
    "Looking at the metrics, we are better off <b>first_review and last_review</b> columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['first_review', 'last_review']\n",
    "detailed_listings.drop(columns = cols_to_drop, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85511498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_response_rate(x):\n",
    "    \"\"\"\n",
    "    eliminating the \"%\" at the end of response rate value\n",
    "    and returning it into float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(str(x[:-1]))/100\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "detailed_listings.host_response_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after\n",
    "detailed_listings.host_response_rate = detailed_listings.host_response_rate.apply(lambda x: transform_response_rate(x))\n",
    "detailed_listings.host_acceptance_rate = detailed_listings.host_acceptance_rate.apply(lambda x: transform_response_rate(x))\n",
    "print(detailed_listings.host_response_rate.head())\n",
    "detailed_listings.host_acceptance_rate .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb46116",
   "metadata": {},
   "source": [
    "Let's handle remaining columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing mean in host_acceptance_rate\n",
    "rate_cols = ['host_acceptance_rate']\n",
    "fill_mean =  lambda col: col.fillna(col.mean())\n",
    "detailed_listings[rate_cols] = detailed_listings[rate_cols].apply(fill_mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49526d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remaining object columns\n",
    "categorical_cols = detailed_listings.select_dtypes(include =['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb99956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_cols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings = detailed_listings.dropna(subset = 'bathrooms_text', axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.head()\n",
    "corr = detailed_listings.corr()\n",
    "plt.figure(figsize=(25,25))\n",
    "_ = sns.heatmap(detailed_listings.corr(), annot=True, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93065b",
   "metadata": {},
   "source": [
    "### Transform remaining object columns to one hot encoding by creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3791c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy(df, cat_cols, dummy_na):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return numerical dataframe after transforming categorical columns\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            df = pd.concat([df.drop(col, axis =1),pd.get_dummies(df[col], prefix = col, prefix_sep = '_', drop_first= True, dummy_na = dummy_na)], axis =1)\n",
    "        except:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = detailed_listings.select_dtypes(include =['object'])\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of columns before handling categorical variables: \", detailed_listings.shape[1])\n",
    "detailed_listings_categorized = create_dummy(detailed_listings, cat_cols, dummy_na = False)\n",
    "print(\"No. of columns after handling categorical variables: \", detailed_listings_categorized.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final dataframe before going into scaling and splitting\n",
    "detailed_listings_categorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c09f1",
   "metadata": {},
   "source": [
    "## Feature Scaling \n",
    "\n",
    "* To enhance the numerical stability of our model and facilitate smoother convergence during the training process, we will preprocess our data by scaling it before fitting it to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63282f4",
   "metadata": {},
   "source": [
    "### we will use standard scaler for price prediction using regression methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "#create a separate dataframe for scaled data.\n",
    "detailed_listings_scaled = pd.DataFrame(data = detailed_listings_categorized)\n",
    "\n",
    "#Separating features and target variable.\n",
    "X = detailed_listings_scaled.drop('price', axis = 1)\n",
    "Y = detailed_listings_scaled.price\n",
    "\n",
    "#stabalize positively skewed target variable\n",
    "Y = boxcox(Y)[0]\n",
    "\n",
    "#splitting into train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaff6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Standard scaler to fit and transform X_train and transform X_test with training set metric values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf693cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fix the positive skew of price column\n",
    "#from scipy.stats import boxcox\n",
    "#y_train_bc = boxcox(y_train)\n",
    "#y_test_bc = boxcox(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50a4b8",
   "metadata": {},
   "source": [
    "boxcox gives two outputs, let's separate our arrays from lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##separating arrays and lamda\n",
    "#\n",
    "##for train\n",
    "#y_train_bc = y_train_bc[0]\n",
    "#lam_train = y_train_bc[1]\n",
    "#\n",
    "##for test\n",
    "#y_test_bc = y_test_bc[0]\n",
    "#lam_test = y_test_bc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports necessary models library\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models evaluation\n",
    "def evaluate(model_name, y_test, predictions):\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    MAE = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    return f'model: {model_name}\\nMean Absolute Error: {MAE}\\nRoot Mean Square Error: {RMSE}\\nR² Score: {round(r2*100, 2)}% \\n--------------------------------------------'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b347ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {'Random Forest':RandomForestRegressor(),\n",
    "          'Lasso':Lasso(),\n",
    "          'ElasticNet': ElasticNet(),\n",
    "          'XGBRegressor': XGBRegressor(),\n",
    "          'Linear Regression': LinearRegression(),\n",
    "          'Linear SVR': LinearSVR(),\n",
    "          'sgdregressor' : SGDRegressor(),\n",
    "          'decision tree': DecisionTreeRegressor(),\n",
    "          'Extra Tree Regressor': ExtraTreesRegressor()\n",
    "}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(evaluate(name, y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae116ddb",
   "metadata": {},
   "source": [
    "* Random Forest model performed the best out of all above.\n",
    "* Though we can we see our models didn't explain much variability\n",
    "* Lots of room for improvement, but at the same time, it could be the bad data as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861e194",
   "metadata": {},
   "source": [
    "### lets see the features which contributes the more to price and then we will move clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(evaluate('Random Forest', y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e1b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot feature importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "X_test_df = pd.DataFrame(X_test, columns = X.columns)\n",
    "barplot_df = pd.DataFrame({'features': model.feature_importances_}, index=X_test_df.columns)\n",
    "barplot_df = barplot_df.sort_values(by='features', ascending=False)\n",
    "barplot_df = barplot_df.iloc[:10]\n",
    "ax.tick_params(axis='x', rotation=18)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "ax.set_title('Features importance')\n",
    "sns.barplot(x=barplot_df.index, y='features', data=barplot_df, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75364e06",
   "metadata": {},
   "source": [
    "* As evident, the most influential factor impacting price is the location, which comes as no surprise. \n",
    "* Following closely is the number of occupants, and subsequently, the room type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8dd75",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb4f4b",
   "metadata": {},
   "source": [
    "### What is the most expensive month to visit Rio de Janeiro?\n",
    "* Analysis of curve shows that listings price soars up during end of year, considering the new year.\n",
    "* Probably because of the availability of house drops by huge margin which is in inverse relation with price\n",
    " shown by graph.\n",
    "\n",
    "### Most and least expensive Neighbourhood in Rio de Janeiro?\n",
    "* The most expensive Rio Neighbourhood is São Cristóvão , followed by Estácio and Joá shown by raw data graph.\n",
    "\n",
    "\n",
    "### What are the factors associated with price of listings?\n",
    "* Location (Latitude)\n",
    "* Number of peopel (accomodates)\n",
    "* Room Type (private room)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0d477",
   "metadata": {},
   "source": [
    "# Conducting another EDA for regression on better RIO Airbnb dataset\n",
    "\n",
    "\n",
    "* Following content on notebook, I will be conducting an exploratory data analysis (EDA) using a newly acquired dataset that offers significant improvements over the previous data used in a prior analysis. The previous dataset, while informative, had several limitations and inconsistencies that hindered the accuracy and depth of our analysis.\n",
    "\n",
    "* After thorough research and data reviews on platforms like Kaggle, I was able to procure a more reliable and comprehensive [dataset](https://www.kaggle.com/datasets/allanbruno/airbnb-rio-de-janeiro/data) for the same analysis. This new dataset not only addresses the shortcomings of the previous data but also provides additional insights and features that were previously unavailable.\n",
    "\n",
    "* The objective of this analysis remains unchanged: to uncover factors influencing prices of listings, our 3rd question of interest. However, with the improved dataset, we expect to gain more accurate and actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d095948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/total_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3993919",
   "metadata": {},
   "source": [
    "* We are only going to work with chosen features which we feel have affects on price of price of listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ed1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/total_data.csv', index_col=False, usecols=['host_is_superhost', 'host_listings_count', 'latitude', 'longitude',\n",
    "       'property_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "       'amenities', 'price', 'require_guest_profile_picture',\n",
    "       'require_guest_phone_verification', 'security_deposit','cleaning_fee'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of the data\n",
    "print('number of rows: ', df.shape[0])\n",
    "print('number of columns: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281738cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb2d21",
   "metadata": {},
   "source": [
    "### We are doing the same feature engineering as we did above, so we will go little quick from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d060c9c",
   "metadata": {},
   "source": [
    "* As we can see, we still have some outliers but looking at the mean, quartile ranges of bathroom, bedrooms and bed, it still looks stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a05a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datatypes of columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50755a8",
   "metadata": {},
   "source": [
    "* As we can notice, price, security_deposit and cleaning_fee are object data type which we need to clean later.\n",
    "* Accomodates and host listing count should be int as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1339d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#number of null value in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87466349",
   "metadata": {},
   "source": [
    "Lots of missing values in security_deposit and cleaning_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25b3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_rows = df.shape[0]\n",
    "print(\"security_deposit missing values are in \",round(361064*100/total_rows),\"% of rows, and cleaning_fee missing values are in \",round(269336*100/total_rows),\"% of rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542edc9c",
   "metadata": {},
   "source": [
    "As one can see, percentage of missing values in above columns, it's better to drop the whole columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop of security_deposit and cleaning_fee columns\n",
    "cols_to_drop = ['security_deposit','cleaning_fee']\n",
    "df.drop(columns = cols_to_drop, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b661030",
   "metadata": {},
   "source": [
    "now let's drop the rows of missing columns, which we can afford to do that as we have more than enough data for doing regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop missing rows\n",
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data types\n",
    "#host_listings_count\n",
    "df['host_listings_count'] = df['host_listings_count'].astype(np.float32, copy=False)\n",
    "df['host_listings_count'] = df['host_listings_count'].astype(np.int16, copy=False)\n",
    "#accommodates\n",
    "df['accommodates'] = df['accommodates'].astype(np.int16, copy=False)\n",
    "#price\n",
    "df['price'] = df['price'].str.replace('$', '', regex=False)\n",
    "df['price'] = df['price'].str.replace(',', '', regex=False)\n",
    "df['price'] = df['price'].astype(np.float32, copy=False)\n",
    "df['price'] = df['price'].astype(np.int32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9cb3a",
   "metadata": {},
   "source": [
    "### quickly get rid of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90795d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db242640",
   "metadata": {},
   "source": [
    "Little changes required in above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the maximum limit value, beyond which data points can be considered outliers.\n",
    "def get_max_fence(column):\n",
    "    qt = df[column].quantile([0.25,0.75])\n",
    "    upper = qt.values[1]\n",
    "    iqr = upper-qt.values[0]\n",
    "    max_fence = upper + 1.5*(iqr)\n",
    "    return max_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ae85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns two seaborn boxplots with one zoomed in around interquartile range\n",
    "def box_plot(column):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(16,6)\n",
    "    _ = sns.boxplot(x=df[column], ax = ax1)\n",
    "    ax1.set_title(f'{column} boxplot')\n",
    "    ax2.set_title(f'Zooming in the {column} boxplot')\n",
    "    ax2.set_xlim((-0.1,1.1*get_max_fence(column)))\n",
    "    _ = sns.boxplot(x=df[column], ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec22473",
   "metadata": {},
   "outputs": [],
   "source": [
    "column ='host_listings_count'\n",
    "box_plot(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3896eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "print('values exceeding: ', get_max_fence(column),' are outliers')\n",
    "df = df[df['host_listings_count'] <= get_max_fence('host_listings_count')]\n",
    "print(f'{rows_before- df.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c90a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('host listings count minimum value : ',df.host_listings_count.min()) #it can't be zero otherwise it wouldn't be on dataset, so we will change it to 1.\n",
    "df.loc[df['host_listings_count'] == 0.0, 'host_listings_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce551f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column = 'price'\n",
    "box_plot(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bc089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "print('values exceeding: ', get_max_fence(column),' are outliers')\n",
    "df = df[df['price'] <= get_max_fence('price')]\n",
    "print(f'{rows_before- df.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ddec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df.price, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1fe4fd",
   "metadata": {},
   "source": [
    "* a positive skewed target variable, which we will normalize before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'beds'\n",
    "box_plot(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "print('values exceeding: ', get_max_fence(column),' are outliers')\n",
    "df = df[df['beds'] <= get_max_fence('beds')]\n",
    "print(f'{rows_before- df.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'accommodates'\n",
    "box_plot('accommodates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c11950",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "print('values exceeding: ', get_max_fence(column),' are outliers')\n",
    "df = df[df['accommodates'] <= get_max_fence('accommodates')]\n",
    "print(f'{rows_before- df.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd989c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature engineering for property_type column\n",
    "property_value_counts = df.property_type.value_counts()\n",
    "values_to_replace = property_value_counts[property_value_counts<1000].index\n",
    "df.property_type.replace(values_to_replace, 'other_types', inplace = True)\n",
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1170f17",
   "metadata": {},
   "source": [
    "### There were lots of important feature in previous dataset consist of missing values and unstable data\n",
    "* no. of beds\n",
    "* no. of bedrooms\n",
    "* no. of bathrooms\n",
    "* amenities\n",
    "\n",
    "We have decided to handle the 'amenities' column differently in this analysis. Instead of assigning unique labels to each amenity, which could lead to a cumbersome and complex representation, we will treat the column as a count of the number of amenities (n_amenities) provided in each listing. By doing so, we simplify the feature while still capturing the essence of the amenities offered by each listing. This approach allows us to retain the valuable information about amenities without introducing unnecessary complexity into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0fd82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['n_amenities'] = df['amenities'].str.split(',').apply(len)+1\n",
    "df['n_amenities'] = df['n_amenities'].astype('int')\n",
    "df.loc[df['amenities'] == {}, 'n_amenities'] = df['n_amenities'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9fa18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column = 'n_amenities'\n",
    "box_plot(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "print('values exceeding: ', get_max_fence(column),' are outliers')\n",
    "df = df[df['n_amenities'] <= get_max_fence('n_amenities')]\n",
    "print(f'{rows_before- df.shape[0]} rows were deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70529b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot pairplot with normal distribution and correlation\n",
    "sns.pairplot(df, diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45401a",
   "metadata": {},
   "source": [
    "* As we can notice, nothing fancy here, distribution looks ok and not much collinearity on those scatter plots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e5ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include =['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f22d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = ['host_is_superhost',\n",
    "               'require_guest_profile_picture',\n",
    "               'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2712f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode above object columns\n",
    "\n",
    "df_label_encoder = df.copy()\n",
    "\n",
    "\n",
    "#convert t and f value to 1 and 0, t being 1.\n",
    "for column in object_cols:\n",
    "    df_label_encoder.loc[df_label_encoder[column] == 'f', column] = 0\n",
    "    df_label_encoder.loc[df_label_encoder[column] == 't', column] = 1\n",
    "    df_label_encoder[column] = df_label_encoder[column].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8de7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "df_label_encoder['property_type'] = encoder.fit_transform(df_label_encoder['property_type']) \n",
    "df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoder.drop(columns = ['amenities'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68449ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into features and target variable\n",
    "y = df_label_encoder['price']\n",
    "X = df_label_encoder.drop(columns = ['price'], axis=1)\n",
    "\n",
    "#boxcox transformation for positively skewed target variable\n",
    "#y = boxcox(y+0.01)[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Standard scaler to fit and transform X_train and transform X_test with training set metric values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11b06c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#models scores\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(evaluate(name, y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7897c",
   "metadata": {},
   "source": [
    "### Insight\n",
    "\n",
    "* The Extra Tree Regressor performed significantly better in explaining the variability in the data.\n",
    "* Compared to the previous dataset, this dataset appears to be more stable, and consequently, the model results are considerably improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot feature importance\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "X_test_df = pd.DataFrame(X_test, columns = X.columns)\n",
    "barplot_df = pd.DataFrame({'features': model.feature_importances_}, index=X_test_df.columns)\n",
    "barplot_df = barplot_df.sort_values(by='features', ascending=False)\n",
    "barplot_df = barplot_df.iloc[:10]\n",
    "ax.tick_params(axis='x', rotation=18)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "ax.set_title('Features importance')\n",
    "sns.barplot(x=barplot_df.index, y='features', data=barplot_df, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e89e17",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "### After conducting the regression analysis, we can draw the following conclusions:\n",
    "\n",
    "* Location variables such as latitude and longitude have the most significant impact on the property price.\n",
    "* This is followed by the number of people the property accommodates, indicating the property's capacity.\n",
    "* The number of amenities also plays a notable role, suggesting the property's overall quality and condition.\n",
    "* Notably, these findings closely resemble those observed in the previous dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
